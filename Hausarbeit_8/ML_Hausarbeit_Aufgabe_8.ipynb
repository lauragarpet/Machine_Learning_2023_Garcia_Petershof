{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Hausarbeit 8\n",
        "\n",
        "• Modifizieren Sie das ResNet Beispiel aus dem Buch so, dass es dem\n",
        "Netzwerk aus dem Paper “Wide Residual Networks” von Zagoruyko et al.\n",
        "entspricht <br>\n",
        "• Verwenden Sie die gleichen Augmentation Methods wie in dem Paper\n",
        "(RandomHorizontalFlip und RandomCrop)<br>\n",
        "• Vergleichen Sie die Accuracy (Erkennungsraten) für Trainings- und\n",
        "Validierungsdaten mit dem Beispiel aus dem Buch<br>\n",
        "• Das Netzwerk dabei nur für die Klassifikation von Vögeln und Flugzeugen\n",
        "trainieren.<br>\n",
        "• Verwenden Sie 28 B(3,3) Layer mit k=2, [WRN-28-2-B(3,3)]<br>"
      ],
      "metadata": {
        "id": "QXK2rBazEGSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.Schritt: Laden der notwendigen Bibliotheken"
      ],
      "metadata": {
        "id": "QAqz-9x5ENkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8rmHHUNTgArw"
      },
      "outputs": [],
      "source": [
        "# Laden der notwendigen Bibliotheken\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import collections\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import datetime\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.Schritt: Laden der Bilddaten aus dem CIFAR10-Datensatz. Klassen: Vögel und Flugzeuge"
      ],
      "metadata": {
        "id": "xfOgwRtDEXdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition der einzelnen Klassen\n",
        "class_names_bird_plane = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "# Laden des Datensatzes: Umwandlung in einen Tensor und Normalisierung der Daten\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "\n",
        "# Trainingsdatensatz\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                     (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "# Validierungsdatensatz\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "# Bildung eines neuen Datensatzes, nur mit Bird und Flugzeug Bildern\n",
        "label_map = {0: 0, 2: 1}\n",
        "class_names_bird_plane = ['airplane', 'bird']\n",
        "\n",
        "# Trainingsdatensatz\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "\n",
        "# Validierungsdatensatz\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WItwjp86gDKx",
        "outputId": "fb43e35b-5e7d-4d8a-d12b-e9e7a7530efc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.Schritt: Definition des ursprünglichen Modells mit dem 3x3-Kernel (Residual-Block aus dem Buch):\n"
      ],
      "metadata": {
        "id": "BXETtzl7EtIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition Residual-Block für ein neuronales Netzwerk\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "\n",
        "        # Zur Initialisierung des RES-Blocks Pbjekts wird ein Konstruktor gebildet.\n",
        "        super(ResBlock, self).__init__()\n",
        "        # 2D-Faltungsoperation mit einer 3x3 Kernel-Größe und einem Padding von 1.\n",
        "        # n_chans = Eingangskanäle und Ausgangskanäle\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)\n",
        "        # Definition einer Batch-Normalisierung, die auf n_features angewendet wird.\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        # Gewichtung der Faltung mit der Kaiming-Normalisierung --> Abgestimmt auf die ReLU-Aktivierungsfunktion\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        # Gewichte der Batch-Normalisierung werden auf den Wert 0.5 gesetzt.\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        # Biases der Batch-Normalisierung werden gleich 0 gesetzt.\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "# Definition der Forward-Methode\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 1. Layer\n",
        "        # Der Eingabetensor x wird durch die Faltung (self.conv) geleitet,\n",
        "        # um eine Zwischenausgabe out zu erhalten.\n",
        "        out = self.conv(x)\n",
        "        # 2. Layer\n",
        "        # Die Zwischenausgabe out wird durch die Batch-Normalisierung\n",
        "        # (self.batch_norm) geleitet, um normierte Features zu erhalten.\n",
        "        out = self.batch_norm(out)\n",
        "        # 3. Layer\n",
        "        # Die normierten Features werden durch die ReLU-Aktivierungsfunktion\n",
        "        # geleitet (torch.relu).\n",
        "        out = torch.relu(out)\n",
        "        # Die Zwischenausgabe out wird mit dem Eingabetensor x addiert,\n",
        "        # um den Residual-Verbindung zu implementieren.\n",
        "        return out + x\n",
        "\n",
        "# Definition des neuronalen Netzwerks mit Residualblöcken\n",
        "class NetResDeep(nn.Module):\n",
        "\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "\n",
        "        # Konstrukur, um das NetResDeep-Objekt zu initialisieren\n",
        "        super().__init__()\n",
        "        # Festlegung der Kanäle (Channels), die in der ersten Faltungsschicht verwendet werden sollen.\n",
        "        # Hier = 32\n",
        "        self.n_chans1 = n_chans1\n",
        "        # Definition einer 2D-Faltungsschicht, die einen Eingabetensor mit 3 Kanälen (RGB-Bild) nimmt und\n",
        "        # n_channel Ausgangskanäle erzeugt.\n",
        "        # Kernel: 3x3 und Padding: 1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        # Definition einer Sequenz von Residual-Blöcken\n",
        "        # Die Sequenz: es wird n_blocks-mal ein Residualblock mit n_chans1 Kanälen\n",
        "        # erstellt und in die Sequenz eingefügt.\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        # Definition eines vollständig verbundenen Layers\n",
        "        # Unter der Annahme, dass der Input nach dem Pooling 8x8 groß ist.\n",
        "        # Ausgabevektor ist danach 32-Groß\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        # Definition zweiter vollständig verbundener Layer\n",
        "        # Eingabevektor = 32 und Ausgabevektor = 2\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "# Definition der Forward-Methode\n",
        "    def forward(self, x):\n",
        "        # Der Eingabetensor x wird durch die erste Faltung (self.conv1)\n",
        "        # geleitet und dann mit der ReLU-Aktivierungsfunktion und einer\n",
        "        # 2x2-Max-Pooling-Operation verarbeitet.\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        # Die verarbeiteten Features werden durch die Sequenz von\n",
        "        # Residualblöcken (self.resblocks) geleitet.\n",
        "        out = self.resblocks(out)\n",
        "        # Die resultierenden Features werden erneut mit einer\n",
        "        # 2x2-Max-Pooling-Operation verarbeitet.\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        # Die resultierenden Features werden in einen Vektor umgeformt\n",
        "        # (out.view(-1, 8 * 8 * self.n_chans1)), um sie für\n",
        "        # den vollständig verbundenen Layer vorzubereiten.\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        # Der umgeformte Vektor wird durch den ersten vollständig verbundenen\n",
        "        # Layer (self.fc1) mit ReLU-Aktivierung geleitet.\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        # Die resultierenden Features werden durch den zweiten vollständig\n",
        "        # verbundenen Layer (self.fc2) geleitet, um den endgültigen Ausgabevektor zu erhalten.\n",
        "        out = self.fc2(out)\n",
        "        # Der Ausgabevektor wird zurückgegeben.\n",
        "        return out\n",
        "\n",
        "# Definition des Trainingloops\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))\n",
        "\n",
        "# Trainieren des Modells\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model_Net_Res = NetResDeep(n_chans1=32, n_blocks=28).to(device=device) # Model\n",
        "optimizer = optim.SGD(model_Net_Res.parameters(), lr=1e-2) # Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()  # Loss-Funktion\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model_Net_Res,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "# Berechnung der Genauigkeit des Modells für die Trainings und Validierungsdaten:\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "\n",
        "validate(model_Net_Res, train_loader, val_loader)\n",
        "print(\"Number of free parameters in the model:\",sum(p.numel() for p in model_Net_Res.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8NRYDwvEy1T",
        "outputId": "dd16cfe8-7abb-4c60-96fd-0879d0752106"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 12:57:48.908705 Epoch 1, Training loss 1.11557389786289\n",
            "2023-06-19 12:58:04.787877 Epoch 10, Training loss 0.2743010007936484\n",
            "2023-06-19 12:58:22.389566 Epoch 20, Training loss 0.1885548646852469\n",
            "2023-06-19 12:58:39.786741 Epoch 30, Training loss 0.11330985504493213\n",
            "2023-06-19 12:58:57.433600 Epoch 40, Training loss 0.06318548567308362\n",
            "2023-06-19 12:59:15.020603 Epoch 50, Training loss 0.09134652771820925\n",
            "2023-06-19 12:59:32.397530 Epoch 60, Training loss 0.06883334765614123\n",
            "2023-06-19 12:59:49.703252 Epoch 70, Training loss 0.014727749402603657\n",
            "2023-06-19 13:00:07.363924 Epoch 80, Training loss 0.014398649451693602\n",
            "2023-06-19 13:00:24.570629 Epoch 90, Training loss 0.0889885771224738\n",
            "2023-06-19 13:00:41.975524 Epoch 100, Training loss 0.04143749161736126\n",
            "Accuracy train: 0.87\n",
            "Accuracy val: 0.79\n",
            "Number of free parameters in the model: 75810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.Schritt: WRN: Wide Residual Network\n",
        "\n",
        "**Anforderungen an das Netzwerk:**\n",
        "- Augmentation Methoden: RandomHorizontalFlip und RandomCrop\n",
        "\n",
        "- Sie 28 B(3,3) Layers mit k=2, [WRN-28-2-B(3,3)]\n"
      ],
      "metadata": {
        "id": "pFb4LpWdE5uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition des Residual-Blocks für das neuronale Netzwerk\n",
        "class WRN_Block(nn.Module):\n",
        "    # Übergabe der Anzahl der Channels und des Strides\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(WRN_Block, self).__init__()\n",
        "        # Batch-Normalisierung der Anzahl der in_channels\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        # ReLU-Aktivierungsfunktion\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        # 1. Convolutional-Layer im Block.\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # Batch-Normalisierung definiert mit der Anzahl der out_channels\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        # RelU-Aktivierungsfunktion\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        # 2. Convolutional-Layer im Block\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        # Anpassung, falls in_channels != out_channels\n",
        "        self.adjust = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),)\n",
        "\n",
        "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
        "                                      nonlinearity='relu')\n",
        "\n",
        "        torch.nn.init.constant_(self.bn1.weight, 0.5)\n",
        "        torch.nn.init.constant_(self.bn2.weight, 0.5)\n",
        "\n",
        "        torch.nn.init.constant_(self.bn1.bias, 0.0)\n",
        "        torch.nn.init.constant_(self.bn2.bias, 0.0)\n",
        "\n",
        "    # Definition der Forward-Methode\n",
        "    def forward(self, input):\n",
        "        # Anwendung der ersten Batch-Normalisierung\n",
        "        out = self.bn1(input)\n",
        "        # Anwendung der ersten ReLU-Aktivierungsfunktion\n",
        "        out = self.relu1(out)\n",
        "        # Anwendung des ersten Convolutional Layers\n",
        "        out = self.conv1(out)\n",
        "        # Anwendung der zweiten Batch-Normalisierung\n",
        "        out = self.bn2(out)\n",
        "        # Anwendung der zweiten ReLU-Aktivierungsfuntkion\n",
        "        out = self.relu2(out)\n",
        "        # Anwendung des zweiten Convolutional Layers\n",
        "        out = self.conv2(out)\n",
        "        # Anpassung der Eingabe, sodass zwischen den Blöcken keine Probleme mit unterschiedlich großen Eingabewerten entsteht.\n",
        "        if input.size() != out.size():\n",
        "            # Anwendung des zusätzlichen Convolutional Layers, falls die Dimensionen zwischen den Blöcken nicht passen.\n",
        "            input = self.adjust(input)\n",
        "\n",
        "        return out + input\n",
        "\n",
        "# Definition des künstlichen neuronalen Netzes\n",
        "class WRN(nn.Module):\n",
        "    # Übergabe der Anzahl der Blöcke, der Weite der Layers und die Anzahl der vorhandenen Klassen\n",
        "    def __init__(self, num_blocks=4, k=2, num_classes=2):\n",
        "        super(WRN, self).__init__()\n",
        "        # Anzahl der input-Channels\n",
        "        self.in_channels = 16\n",
        "        # Definition des ersten Convolutional-Layers vor den Residual-Blöcken (convolutional group 1: 16)\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        # Definition der ReLU-Aktivierungsfunktion\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        ### Definition der Übergabeparameter für die Blöcke\n",
        "        # Convolutional group 2: 16*k, num_blocks: Anzahl von Blöcken innerhalb der Gruppe.\n",
        "        self.group_conv2 = self.block(16*k, num_blocks)\n",
        "        # Convolutional group 3: 32*k\n",
        "        self.group_conv3 = self.block(32*k, num_blocks, stride=2)\n",
        "        # Convolutional group 4: 64*k\n",
        "        self.group_conv4 = self.block(64*k, num_blocks, stride=2)\n",
        "\n",
        "        # Definition der Batch-Normalisierung\n",
        "        self.bn = nn.BatchNorm2d(64*k)\n",
        "        # Definition des Average Poolings\n",
        "        self.avg_pool = nn.AvgPool2d(8, stride=1)\n",
        "        # Definition des Linearisierungsfunktion, mit 64*k Neuronen, die zu num_classes = 2 transferiert werden.\n",
        "        self.fc = nn.Linear(64*k, num_classes)\n",
        "\n",
        "    # Erzeugung einer Sequenz aus mehreren (num_blocks) Residual Blöcken\n",
        "    # Übergabe der Anzahl der Output-Channels und der Anzahl der N-Residual Blöcken\n",
        "    def block(self, out_channels, num_blocks=4, stride=1):\n",
        "        # Leere Liste für die einzelnen Residual-Blöcke\n",
        "        sequence_of_blocks = []\n",
        "        sequence_of_blocks.append(WRN_Block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            sequence_of_blocks.append(WRN_Block(out_channels, out_channels))\n",
        "        return nn.Sequential(*sequence_of_blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        input = x\n",
        "        # 1. Convolutional-Layer vor den Blöcken\n",
        "        out_group_conv1 = self.conv1(input)\n",
        "        # 2. Gruppe: Conv2 - 16*k\n",
        "        out_group_conv2 = self.group_conv2(out_group_conv1)\n",
        "        # 3. Gruppe: Conv3 - 32*k\n",
        "        out_group_conv3 = self.group_conv3(out_group_conv2)\n",
        "        # 4. Gruppe: Conv4 - 64*k\n",
        "        out_group_conv4 = self.group_conv4(out_group_conv3)\n",
        "\n",
        "        # Anwendung der Batch-Normalisierung auf das Ergebnis nach den Blöcken\n",
        "        out = self.bn(out_group_conv4)\n",
        "        # Anwendung der ReLU-Aktivierungsfunktion\n",
        "        out = self.relu(out)\n",
        "        # Anwendung des Avg-Poolings\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # Anwendung der Linearisierungsfunktion\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Definition des Training-Loops\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))\n",
        "\n",
        "# Trainieren des Modells\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "\n",
        "model = WRN().to(device=device) # Modell\n",
        "lr = 3e-1 # Lernrate\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr) # Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss() # Loss-Funktion\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "\n",
        "# Berechnung der Genauigkeit des Modells für die Trainings und Validierungsdaten:\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1)\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)\n",
        "print(\"Number of free parameters in the model:\",sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNwd5fiIgbhy",
        "outputId": "5d588aef-b1c0-4c33-bfad-d48309c7ed5f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 12:46:28.553358 Epoch 1, Training loss 0.4513682360482064\n",
            "2023-06-19 12:46:48.517420 Epoch 10, Training loss 0.12106433641284135\n",
            "2023-06-19 12:47:10.847435 Epoch 20, Training loss 0.021550760945159893\n",
            "2023-06-19 12:47:33.593666 Epoch 30, Training loss 0.0017710104834949775\n",
            "2023-06-19 12:47:55.581966 Epoch 40, Training loss 0.00015372756504826137\n",
            "2023-06-19 12:48:17.640569 Epoch 50, Training loss 0.0017521342471728373\n",
            "2023-06-19 12:48:39.683709 Epoch 60, Training loss 0.00024295221881367782\n",
            "2023-06-19 12:49:01.705011 Epoch 70, Training loss 0.0013621689838036201\n",
            "2023-06-19 12:49:23.776445 Epoch 80, Training loss 0.0002636750655748439\n",
            "2023-06-19 12:49:45.832560 Epoch 90, Training loss 0.00021758072122045945\n",
            "2023-06-19 12:50:07.934912 Epoch 100, Training loss 0.00021671975004583898\n",
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.93\n",
            "Number of free parameters in the model: 1531090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vergleich der Erkennungsraten: (NetResDeep und WRN)\n",
        "\n",
        "Es ist erkenntlich, dass die Genauigkeit des Modells durch die Verwendung eines Wide Residual Netzwerks verbessert werden kann.\n",
        "Das NetResDeep-Model, welches eine Tiefe von 28 besitzt und lediglich einzelne Res-Blöcke hintereinander verwendet, besitzt eine Genauigkeit auf die Validierungsdaten von 79 %.\n",
        "Dahingegen besitzt das Wide Residual Netzwerk, welches auf der Grundlage des Papers (https://arxiv.org/abs/1605.07146) implementiert wurde, eine Genauigkeit von 93 % auf die Validierungsdaten und ist folglich deutlich präziser. Hierbei besteht das Modell aus 28 Layern, aufgeteilt in vier Blöcke mit einer Weite von k = 2."
      ],
      "metadata": {
        "id": "33-0pddIv7bo"
      }
    }
  ]
}